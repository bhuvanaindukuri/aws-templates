### S3
- Defined at region level
- Key will be full path (prefix + object name)
- More than 5GB should be uploaded as Multi-part upload
- Max object size is 5TB
- Metadata - List of key value pairs
- Tags 
  - Max 10
  - useful for security / lifecycle
- Version Id - If versioning enabled
- Folders can be created


#### S3 Security
- User based
    - IAM policies
- Resource based
    - Bucket policies - Most frequently used
    - Object ACLs
    - Bucket ACLs

Note: Final access = IAM policy allow **or** resource policy allows **and** no explicit deny

- Encryption can be done using security keys

#### S3 websites
- URL looks like <bucket-name>.s3-website-<AWS Region>.amazonaws.com or <bucket-name>.s3-website.<AWS Region>.amazonaws.com

#### S3 Versioning
- Enabled at bucket level
- Any file not versioned will have version null
- Suspending versions does not delete previous versions
- Version id is like hashkey
- Version delete is permanent
- If version is not available, it is only marked for deletion. A new version is created with status as Marked for deletion

#### S3 replication
- Asynchronous
- Must enable versioning
- Buckets can be in different accounts
- Can be applied to all objects or specify filter rules
- Objects added before enabling replication are not included. "S3 batch Replcation" can be used for replicating existing objects.
- Types
    - Cross Region Replication (CRR)
    - Same Region Replication (SRR)
- No chaining of replication
- Version ids remain the same for the replicated objects in the target
- Delete marker deletion can be replicated by enabling 
  
#### S3 Storage classes
- Amazon S3 Standard - General purpose
    - Low latency
    - High throughput
- Amazon S3 Standard - IA
    - Slightly lower availability (99.9%)
    - Rapid access when needed
    - Cheaper than S3 standard
- Amazon S3 One Zone - IA
    - Slightly lower availability (99.5%)
    - One AZ only
    - Rapid access when needed
- Amazon S3 Glacier Instant retrieval
    - Millisecond retrieval
    - Min storage duration 90 days
- Amazon S3 Glacier Flexible retrieval
    - Expedited (1 to 5 mins)
    - Standard (3 to 5 hours)
    - Bulk ( 5 to 12 hours)
    - Min storage duration 90 days
- Amazon S3 Glacier Deep Archive
    - Standard 12 hours
    - Bulk 48 hours
    - Minimum storage duration of 180 days
- Amazon S3 Intelligent Tiering
    - Automatic moves between tiers based on number of days of access
    - Monthly monitoring fee & auto-tiering fee

#### Lifecycle rules
- Can be set for following 
  - Move current versions between storage classes
  - Move noncurrent versions between storage classes
  - Expire current version of objects
  - Permanently delete non current versions
  - Delete expired object delete markers or incomplete multipart uploads
  
#### S3 requester pays
- Requester pays for the networking cost of the download
- Requester must be authenticated

#### S3 Event Notifications
- Ex- S3:ObjectCreated, S3:ObjectRemoved, S3:ObjectRestore, S3:Replication…
- Object name filtering possible (*.jpg)
- Target can be SNS, SQS, Lambda function
- New target added recently - Eventbridge. All events will be sent to EventBridge.
- To allow S3 to send notifications to SQS, the principal in the policy could be configured as 
  "Principal": {
                "Service": "s3.amazonaws.com"
            },
 
 #### S3 Baseline Performance
 - 3,500 PUT/COPY/POST/DELETE or 5,500 GET/HEAD requests per second per prefix in a bucket
 - no limits to the number of prefixes in a bucket
 - Path between bucket and key is considered as prefix
  
#### S3 Performance
- Multi-Part upload
  - Recommended for files > 100MB, must use for files > 5GB
  - Can help parallelize uploads
- S3 Transfer Acceleration
  - Increase transfer speed by transferring file to an AWS edge location which will forward the data to the S3 bucket in the target region
  - Compatible with multi-part upload
- S3 Byte-range fetches
  - Parallelize GETs by requesting specific byte ranges
  - Better resilience in case of failures
  - Can help speed up downloads or get partial data like header

#### S3 Select
- Retrieve less data using SQL by performing server-side filtering
- Can filter by rows & columns (simple SQL statements)
- Less network transfer, less CPU cost client-side
  
#### S3 Batch operations
- Perform bulk operations on existing S3 objects with a single request, example:
  - Modify object metadata & properties
  - Copy objects between S3 buckets
  - Encrypt un-encrypted objects
  - Modify ACLs, tags
  - Restore objects from S3 Glacier
  - Invoke Lambda function to perform custom action on each object
- A job consists of a list of objects, the action to perform, and optional parameters
- S3 Batch Operations manages retries, tracks progress, sends completion notifications, generate reports …
- You can use S3 Inventory to get object list and use S3 Select to filter objects
#### S3 Encryption
- Can be set at bucket or object level
- Can be overridden
- Versioning should be enabled
  - When encryption method is changed at the object level, new version is created
- Possible to force encryption using bucket policies
  
#### S3 Encryption Types
- Server-Side Encryption (SSE)
  - Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3) 
    – Enabled by Default
    - Encrypts S3 objects using keys handled, managed, and owned by AWS
    - Type: AES-256 Must set header "x-amz-server-side-encryption": "AES256"  
  - Server-Side Encryption with KMS Keys stored in AWS KMS (SSE-KMS)
    - Leverage AWS Key Management Service (AWS KMS) to manage encryption keys
    - Key usage can be tracked using cloudTrail
    - Must set header "x-amz-server-side-encryption": "aws:kms" 
    - Each upload & download counts towards KMS Quota per second
  - Server-Side Encryption with Customer-Provided Keys (SSE-C)
    - When you want to manage your own encryption keys
    - The key should be provided for both upload & download
    - Https only
    - Only supported by CLI & SDK and not in console
- Client-Side Encryption
    - Encrypted file is sent to the API

#### S3 MFA Delete
- To use MFA delete versioning should be enabled
- Enabling can be done only from CLI
- Permanent deletion can also be done only from CLI when MFA is enabled
  
#### S3 Pre-Signed URL
- URL Expiration
  - S3 Console - 1 min to 12 hours
  - AWS CLI - Max: 168 hours
  
#### Glacier Valut Lock
- Adopt a WORM (Write Once Read Many) mode
- Create a Vault Lock Policy 
- Lock the policy for future edits (can no longer be changed or deleted)
- Helpful for compliance and data retention
- Bucket level

#### S3 Object lock
- Adopt a WORM (Write Once Read Many) model
- Block an object version deletion for a specified amount of time
- Retention mode - Compliance:
  - Object versions can't be overwritten or deleted by any user, including the root user
  - Objects retention modes can't be changed, and retention periods can't be shortened
- Retention mode - Governance:
  - Most users can't overwrite or delete an object version or alter its lock settings 
  - Some users have special permissions to change the retention or delete the object
- Retention Period: protect the object for a fixed period, it can be extended 
- Legal Hold: 
  - protect the object indefinitely, independent from retention period
  - can be freely placed and removed using the s3:PutObjectLegalHold IAM permission
 
#### S3 Access Points
- Policies can be set at access point level
- Each Access Point gets its own DNS and policy to limit who can access it
  - A specific IAM user / group
  - One policy per Access Point => Easier to manage than complex bucket policies
  
#### S3 Object Lambda
- Use AWS Lambda Functions to change the object before it is retrieved by the caller application
- Only one S3 bucket is needed, on top of which we create S3 Access Point and S3 Object Lambda Access Points. 
- Use Cases:
  - Redacting personally identifiable information for analytics or non- production environments.
  - Converting across data formats, such as converting XML to JSON.
  - Resizing and watermarking images on the fly using caller-specific details, such as the user who requested the object.
  
Notes
- Storage classes set at object level or by lifecycle rules at bucket level
- S3 Analytics suggests the storage class based on the usage and age of the objects
  - Works only for Standard & Standard IA
- When S3 bucket is used as a static website, CORS settings need to be updated accordingly to be able to invoke from other websites.
  - CORS settings at bucket level helps with this

